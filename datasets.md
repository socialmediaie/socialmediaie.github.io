---
title: List of datasets
layout: post
---

For POS taggin gwe use the dataset from [17,18] (OW), [7] (TIE), [20] (RT), [15](TB), [22] (DS), [12] (FS), and [12,13] (LW). 
For NER, we use the dataset from [20] (RT), [23] (W16), [6] (W17), [9] (FN), [10] (HG),and [4] (BR), [24] (MM), [11] (YD), [21] (we do not evaluate on this) and [1] (MSM). 
The [20] (RT) dataset is also used for chunking, and supersense tagging [14]. 
We also use the [14] (JH) dataset for supersense tagging.


## Dataset references

* [1] Amparo Elizabeth Cano, Andrea Varga, Matthew Rowe, Milan Stankovic, and Aba-Sah Dadzie. 2013. Making Sense of Microposts (#MSM2013) Concept ExtractionChallenge. In#MSM.
* [2] Richard A. Caruana. 1993.  Multitask Learning: A Knowledge-Based Source ofInductive Bias.  InMachine Learning Proceedings 1993. Elsevier, 41–48.   https://doi.org/10.1016/b978-1-55860-307-3.50012-5
* [3] Ronan Collbert, Jason Weston, LÃľon Bottou, Michael Karlen, Koray Kavukcuoglu,and Pavel Kuksa. 2011.  Natural Language Processing (Almost) from Scratch.Journal ofMachine Learning Research12 (2 2011), 2493–2537.   http://dl.acm.org/citation.cfm?id=2078186
* [4] Leon  Derczynski,  Kalina  Bontcheva,  and  Ian  Roberts.  2016.Broad  Twit-ter  Corpus:  A  Diverse  Named  Entity  Recognition  Resource.Proceedings ofCOLING 2016, the 26th International Conference on Computational Linguis-tics: Technical Papers(2016),  1169–1179.http://aclanthology.info/papers/broad-twitter-corpus-a-diverse-named-entity-recognition-resource
* [5] Leon Derczynski, Diana Maynard, Niraj Aswani, and Kalina Bontcheva. 2013.Microblog-genre Noise and Impact on Semantic Annotation Accuracy. InPro-ceedings of the 24th ACM Conference on Hypertext and Social Media (HT ’13). ACM,New York, NY, USA, 21–30.   https://doi.org/10.1145/2481492.2481495
* [6] Leon Derczynski, Eric Nichols, Marieke van Erp, and Nut Limsopatham. 2017.Results of the WNUT2017 Shared Task on Novel and Emerging Entity Recognition.InProceedings of the 3rd Workshop on Noisy User-generated Text. Association forComputational Linguistics, Copenhagen, Denmark, 140–147.  https://doi.org/10.18653/v1/W17-4418
* [7] Leon Derczynski, Alan Ritter, Sam Clark, and Kalina Bontcheva. 2013.  Twit-ter Part-of-Speech Tagging for All: Overcoming Sparse and Noisy Data.Pro-ceedings of the International Conference Recent Advances in Natural LanguageProcessing RANLP 2013(2013),  198–206.http://aclanthology.info/papers/twitter-part-of-speech-tagging-for-all-overcoming-sparse-and-noisy-data
* [8] Jacob Eisenstein. 2013.   What to do about bad language on the internet. InProceedings of the 2013 Conference of the North American Chapter of the Associationfor Computational Linguistics: Human Language Technologies. Association forComputational Linguistics, Atlanta, Georgia, 359–369.   https://www.aclweb.org/anthology/N13-1037
* [9] Tim Finin, William Murnane, Anand Karandikar, Nicholas Keller, Justin Mar-tineau, and Mark Dredze. 2010. Annotating Named Entities in Twitter Data withCrowdsourcing.Proceedings of the NAACL HLT 2010 Workshop on Creating Speechand Language Data with Amazon’s Mechanical Turk2010, January, 80–88.
* [10] Hege Fromreide, Dirk Hovy, and Anders Søgaard. 2014. Crowdsourcing and anno-tating NER for Twitter #drift. InProceedings of the Ninth International Conferenceon Language Resources and Evaluation (LREC’14). European language resourcesdistribution agency, 2544–2547.   http://www.lrec-conf.org/proceedings/lrec2014/pdf/421_Paper.pdf
* [11] Genevieve Gorrell, Johann Petrak, and Kalina Bontcheva. 2015. Using @TwitterConventions to Improve #LOD-Based Named Entity Disambiguation. Springer,Cham, 171–186.  https://doi.org/10.1007/978-3-319-18818-8{_}11
* [12] Dirk Hovy, Barbara Plank, and Anders Søgaard. 2014. Experiments with crowd-sourced re-annotation of a POS tagging data set. InProceedings of the 52ndAnnual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Association for Computational Linguistics, Baltimore, Maryland, 377–382.https://doi.org/10.3115/v1/P14-2062
* [13] Dirk Hovy, Barbara Plank, and Anders Søgaard. 2014.   When POS data setsdon’t add up: Combatting sample bias.Proceedings of the Ninth InternationalConference on Language Resources and Evaluation (LREC-2014)(2014).   https://aclanthology.coli.uni-saarland.de/papers/L14-1402/l14-1402
* [14] Anders Johannsen, Dirk Hovy, HÃľctor Martínez Alonso, Barbara Plank, andAnders Søgaard. 2014.  More or less supervised supersense tagging of Twitter.InProceedings of the Third Joint Conference on Lexical and Computational Se-mantics (*SEM 2014). Association for Computational Linguistics and Dublin CityUniversity, Stroudsburg, PA, USA, 1–11.  https://doi.org/10.3115/v1/S14-1001
* [15] Yijia Liu, Yi Zhu, Wanxiang Che, Bing Qin, Nathan Schneider, and Noah A. Smith.2018.  Parsing Tweets into Universal Dependencies. InProceedings of the 2018Conference of the North American Chapter of the Association for ComputationalLinguistics: Human Language Technologies, Volume 1 (Long Papers). Associationfor Computational Linguistics, New Orleans, Louisiana, 965–975.   https://doi.org/10.18653/v1/N18-1088
* [16] Héctor Martínez Alonso and Barbara Plank. 2017. When is multitask learningeffective? Semantic sequence prediction under varying data conditions. InPro-ceedings of the 15th Conference of the European Chapter of the Association forComputational Linguistics: Volume 1, Long Papers. Association for ComputationalLinguistics, Valencia, Spain, 44–53.  https://www.aclweb.org/anthology/E17-1005
* [17] Olutobi Owoputi, Brendan O’Connor, Chris Dyer, Kevin Gimpel, and NathanSchneider. 2012. Part-of-Speech Tagging for Twitter: Word Clusters and OtherAdvances.Cmu-Ml-12-107(2012).
* [18] Olutobi Owoputi, Brendan O’Connor, Chris Dyer, Kevin Gimpel, Nathan Schnei-der, and Noah a Smith. 2013.   Improved Part-of-Speech Tagging for OnlineConversational Text with Word Clusters.Proceedings of NAACL-HLT 2013June(2013), 380–390.   https://doi.org/10.1.1.343.3572
* [19] Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,Kenton Lee, and Luke Zettlemoyer. 2018.  Deep Contextualized Word Repre-sentations. InProceedings of the 2018 Conference of the North American Chapterof the Association for Computational Linguistics: Human Language Technologies,Volume 1 (Long Papers). Association for Computational Linguistics, New Orleans,Louisiana, 2227–2237.  https://doi.org/10.18653/v1/N18-1202
* [20] Alan Ritter, Sam Clark, and Oren Etzioni. 2011.  Named entity recognition intweets: an experimental study. InProceedings of Emperical Methods for NaturalLangauge Processing. 1524–1534.   https://doi.org/10.1075/li.30.1.03nad
* [21] Giuseppe Rizzo, Marieke van Erp, Julien Plu, and RaphaÃńl Troncy. 2016. MakingSense of Microposts (#Microposts2016) Named Entity rEcognition and Linking(NEEL) Challenge. InWorkshop on Making Sense of Microposts (#Microposts2016).Montréal.   http://ceur-ws.org/Vol-1691/microposts2016_neel-challenge-report/http://ceur-ws.org/Vol-1691/microposts2016_neel-challenge-report/microposts2016_neel-challenge-report.pdfhttp://microposts2016.seas.upenn.edu/challenge.htmlhttp://ceur-ws.org/Vol-1691/mic
* [22] Nathan Schneider and Noah A. Smith. 2015.  A Corpus and Model IntegratingMultiword Expressions and Supersenses. InProceedings of the 2015 Conference ofthe North American Chapter of the Association for Computational Linguistics: Hu-man Language Technologies. Association for Computational Linguistics, Denver,Colorado, 1537–1547.  https://doi.org/10.3115/v1/N15-1177
* [23] Benjamin  Strauss,  Bethany  Toma,  Alan  Ritter,  Marie-Catherine  de  Marn-effe,  and  Wei  Xu.  2016.Results  of  the  WNUT16  Named  Entity  Recog-nition  Shared  Task.Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT)(2016),  138–144.http://aclanthology.info/papers/results-of-the-wnut16-named-entity-recognition-shared-task
* [24] Qi Zhang, Jinlan Fu, Xiaoyu Liu, and Xuanjing Huang. 2018.   Adaptive Co-attention Network for Named Entity Recognition in Tweets.   https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16432
